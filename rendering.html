<!DOCTYPE html>
<html>
  <head>
    <title>Standards for Media and Real Time Communications on the Web</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#0072ff">
    <meta name="apple-mobile-web-app-status-bar-style" content="#0072ff">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,100,300,700,900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="https://w3c.github.io/mediartc-roadmap-ui/assets/css/theme.css">
    <link rel="stylesheet" href="https://w3c.github.io/mediartc-roadmap-ui/assets/css/roadmap.css">
    <link href='https://fonts.googleapis.com/css?family=Droid+Sans:400,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Lora:400,400italic,700,700italic' rel='stylesheet' type='text/css'>
    <link rel="manifest" href="manifest.json">
  </head>
  <body>

    <header>
      <div class="container">
        <button id="side-nav-btn" type="button" name="sidenav-opener"><img src="https://w3c.github.io/mediartc-roadmap-ui/assets/img/icon-humberger.svg" height="15" alt=""></button>


                <div class="brand">
                  <img src="https://w3c.github.io/mediartc-roadmap-ui/assets/img/w3cdevelopers-logo.svg" height="30" alt="">
                </div>
      </div>

    </header>


    <main>
      <div class="content-wrapper">
        <section class="hero">
            <div class="container">
                <h1>Media Rendering</h1>
            </div>
        </section>
        <section class="main-content">
          <div class="container">
        <section class="featureset well-deployed">
          <h2>Well-deployed technologies</h3>
          <p>Few media-based services can usefully function without rendering audio or video content; the HTML5 specification provides widely deployed support for this essential feature:</p>
          <ul>
            <li data-feature="Audio rendering">audio content can be rendered in any Web page via the <a data-featureid="audio"><code>&lt;audio&gt;</code> element</a></li>
            <li data-feature="Video rendering">likewise, video content can be rendered with <a data-featureid="video"><code>&lt;video&gt;</code> element</a></li>
        </section>
        <section class="featureset in-progress">
          <h2>Specifications in progress</h3>
          <p data-feature="Audio rendering">Beyond the declarative approach enabled by the <code>&lt;audio&gt;</code> element, the <a data-featureid="webaudio">Web Audio API</a> provides a full-fledged audio processing API, which includes support for low-latency playback of audio content.</p>
          <div data-feature="Distributed rendering">
            <p>As users increasingly own more and more connected devices, the need to get these devices to work together increases as well.</p>
            <p>The <a data-featureid="secondscreen">Second Screen Presentation API</a> offers the possibility for a Web page to open and control a page located on another screen, opening the road for multi-screen Web applications.</p>
            <p>The <a data-featureid="audio-output">Audio Output Devices API</a> offer a similar functionality for audio streams, enabling a Web application to pick on which audio output devices a given sound should be played.</p>
          </div>
        </section>
        <section class="featureset exploratory-work">
          <h2>Exploratory work</h3>
          <div data-feature="Distributed rendering">
            <p>The <a data-featureid="discovery">Network Service Discovery API</a> offers a lower-level approach to the establishement of multi-device operations, by providing integration with local network-based media renderers, such as those enabled by DLNA, UPnP, etc. At this time, the future of this specification is uncertain, given the difficulty of finding the right balance between the requirements of the Web security model and the desire to be compatible with existing devices.</p>
            <p>The Multi-Device Timing Community Group is exploring another aspect of multi-device media rendering: its <a data-featureid="timing">Timing Object</a> specification enables to keep video, audio and other data streams in close synchrony, across devices and independently of the network topology.</p>
            </div>
        </section>
        <section>
          <h2>Featured not covered by ongoing work</h3>
          <dl>
            <dt>Color Management</dt>
            <dd>To ensure the proper rendering of videos with high-dynamic range and wide-gamut colors, content providers would need to determine whether the underlying device and browser have proper support for this.</dd>
          </dl>
        </section>
</div>
      </section>
        <section class="contribute">
            <div class="container">
                <p>
                    Readers are strongly encouraged to submit their use cases that cannot be achieved today with Web technologies, either by starting a new topic in the <a href="https://discourse.wicg.io/c/mediartc">Media and Real-Time Communications category of W3C’s discourse forum</a> or by raising an <a href="https://github.com/dontcallmedom/mediartc-roadmap/issues/new">issue on the Github repository</a> where this document is maintained.
                </p>
                <p class="call-to-action">
                  <a class="btn" href="https://github.com/dontcallmedom/mediartc-roadmap/">Github</a>
                  <a class="btn reverse" href="https://discourse.wicg.io/c/mediartc">Discourse</a>
                </p>
            </div>
        </section>
      </div>

        </main>

        <aside id="side-nav">
          <nav>
            <ul>
              <li>
                <a href="rendering.html">
                  <div class="description">
                    <p>
                      Media rendering
                    </p>
                  </div>
                </a>
              </li>
              <li>
                <a href="processing.html">
                  <div class="description">
                    <p>
                      Media processing
                    </p>
                  </div>
                </a>
              </li>
              <li>
                <a href="synchronized.html">
                  <div class="description">
                    <p>
                      Synchronized content
                    </p>
                  </div>
                </a>
              </li>
              <li>
                <a href="control.html">
                  <div class="description">
                    <p>
                      Media control
                    </p>
                  </div>
                </a>
              </li>
              <li>
                <a href="transmission.html">
                  <div class="description">
                    <p>
                      Media transmission
                    </p>
                  </div>
                </a>
              </li>
              <li>
                <a href="capture.html">
                  <div class="description">
                    <p>
                      Media capture
                    </p>
                  </div>
                </a>
              </li>
            </ul>
          </nav>
        </aside>
    <div id="mask"></div>
        <footer>
            <div class="container">
                <p>
                    © <a href="https://www.w3.org/">W3C</a> ®
                    <br>
                    <a href="https://www.csail.mit.edu/">MIT</a> · <a href="https://www.ercim.eu/">ERCIM</a> · <a href="https://www.keio.ac.jp/">Keio</a> · <a href="http://ev.buaa.edu.cn/">Beihang</a>
                    <br>
                    Usage policies apply
                </p>
            </div>
        </footer>
        <script type="text/javascript" src="https://w3c.github.io/mediartc-roadmap-ui/assets/js/sidenav.js"></script>
        <script type="text/javascript" src="https://w3c.github.io/mediartc-roadmap-ui/assets/js/app.js"></script>
        <script src="js/generate.js"></script>
    </body>
</html>
